{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "801896dd-7519-4344-8cac-2a9e6ce22a74",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/logo.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8effb5-69b6-41f0-9ffa-bfe164e1f3cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Exercise 1:** Deploying and Initializing PostgreSQL on Kubernetes\n",
    "\n",
    "In this exercise, we will walk through deploying a PostgreSQL database in a Kubernetes environment using Python. This process will involve using Kubernetes ```kubectl``` commands to manage persistent storage (Persistent Volume Claims), deployments, services, and initialization of sample data.\n",
    "\n",
    "You will:\n",
    "- Automate the deployment of PostgreSQL on Kubernetes.\n",
    "- Handle resource management like Persistent Volume Claims (PVC) and deployments.\n",
    "- Set up a PostgreSQL database, create tables, and load sample data.\n",
    "- Implement retry logic for connecting to PostgreSQL and ensure a robust setup.\n",
    "\n",
    "**Steps Overview:**\n",
    "- Step 1: Define functions to interact with Kubernetes resources like PVCs, deployments, and services.\n",
    "- Step 2: Set up PostgreSQL on Kubernetes with proper permission handling.\n",
    "- Step 3: Write code to initialize the database by creating tables and loading sample data.\n",
    "- Step 4: Use Python's psycopg2 library to connect and interact with the PostgreSQL database.\n",
    "- Step 5: Generate and load realistic sample data into PostgreSQL for use in subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2362e7-a150-47cb-9c58-62a72874b55c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Prerequisites:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2755f8c-b0d4-4f73-bb2c-df15c5b17877",
   "metadata": {
    "tags": []
   },
   "source": [
    "As instructed in the [Introductory notebook](./00.introduction.ipynb), ensure that you have run `pip install -r requirements.txt` in a Terminal window, located in the same working directory, prior to running this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bdced2-2f27-46db-ae08-4f85ff96215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama_index llama_index.llms.nvidia llama_index.embeddings.nvidia matplotlib polars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a7dbb-003b-424d-bb37-302ce6493c34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **1. Prepare the environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b154f-70a3-4319-9c31-9e5ad1f0ece0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Important:</b> Set your <b>Username</b> here !\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcbedce-ef91-4e28-b02d-b54e6dcead35",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME=\"vince\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fb2b9-2803-4ed7-9447-86540a24fd21",
   "metadata": {
    "tags": []
   },
   "source": [
    "We start by defining a function to read the Kubernetes namespace from the service account mount point, allowing us to deploy resources in the correct namespace. If not running in a Kubernetes environment, it defaults to the \"default\" namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d9ef1d-e4d4-4d42-acb6-c9abae749939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_namespace_from_service_account():\n",
    "    \"\"\"\n",
    "    Reads the Kubernetes namespace from the service account mount point.\n",
    "    Returns 'default' if not running in a Kubernetes pod or if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    namespace_file = '/var/run/secrets/kubernetes.io/serviceaccount/namespace'\n",
    "    try:\n",
    "        with open(namespace_file, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    except IOError:\n",
    "        return 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2398849-48ae-4be1-8a62-2c70499b66cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "Set the Global variables required to run the exercise smootly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7236a3ce-7885-4d69-998b-255f739cb698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAMESPACE: admin-901d042c\n",
      "POSTGRES_PASSWORD: postgres\n",
      "PG_SERVICE_NAME: vince-retailers-postgres\n",
      "PG_DATABASE_NAME: vince_retailers\n"
     ]
    }
   ],
   "source": [
    "# Global configuration\n",
    "NAMESPACE = get_namespace_from_service_account()\n",
    "POSTGRES_PASSWORD = \"postgres\"\n",
    "PG_SERVICE_NAME = f\"{USERNAME}-retailers-postgres\"\n",
    "PG_DATABASE_NAME = f\"{USERNAME}_retailers\"\n",
    "\n",
    "# Print the result\n",
    "print(\"NAMESPACE:\", NAMESPACE)\n",
    "print(\"POSTGRES_PASSWORD:\", POSTGRES_PASSWORD)\n",
    "print(\"PG_SERVICE_NAME:\", PG_SERVICE_NAME)\n",
    "print(\"PG_DATABASE_NAME:\", PG_DATABASE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d3c36-b5b6-4338-873a-3011f82fddab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **2. PostgreSQL Deployment Logic:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948bf2e-8d11-4a4a-b8a3-62074255169c",
   "metadata": {
    "tags": []
   },
   "source": [
    "We deploy PostgreSQL on Kubernetes by using Python's `subprocess` to execute `kubectl` commands. <br>\n",
    "This ensures the deployment is automated, and the correct Persistent Volume Claim (PVC) and deployment configuration are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a51cc5-8f76-49ef-bf2d-793e4da95f05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deploy_postgresql():\n",
    "    \"\"\"Deploy PostgreSQL with proper permission handling and PVC management\"\"\"\n",
    "    pvc_name = f\"postgres-pvc-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    \n",
    "    # Step 1: Delete any existing deployment to start fresh (if we have permissions)\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            f\"kubectl delete deployment -n {NAMESPACE} {PG_SERVICE_NAME} --ignore-not-found\",\n",
    "            shell=True, check=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Warning: Could not delete existing deployment (may not have permissions): {e}\")\n",
    "\n",
    "    # Step 2: Create PVC only if it doesn't exist\n",
    "    if not resource_exists(\"pvc\", pvc_name, NAMESPACE):\n",
    "        # Create PVC dynamically\n",
    "        create_pvc(pvc_name)\n",
    "    else:\n",
    "        print(f\"Using existing PVC: {pvc_name}\")\n",
    "\n",
    "    # Step 3: Create PostgreSQL deployment\n",
    "    create_postgres_deployment(pvc_name)\n",
    "\n",
    "    # Step 4: Check if Service is created\n",
    "    create_postgres_service()\n",
    "\n",
    "    print(\"Waiting for PostgreSQL to initialize...\")\n",
    "    time.sleep(30)\n",
    "\n",
    "    # Step 5: Check Pod status\n",
    "    check_pod_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922dfac2-2f13-4b17-9e01-cd7cee98f55a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **4. Database Connection and Retry Logic:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acafe4dd-7c94-4416-a505-fb25558a614b",
   "metadata": {
    "tags": []
   },
   "source": [
    "To interact with the PostgreSQL database, we use `psycopg2` to connect to the database. <br>\n",
    "We implement retry logic in case the database is not yet available after the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec57b1b-3c0e-40ae-a1a0-cc79ad56e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection(retries=3, delay=5):\n",
    "    \"\"\"Get connection with retries\"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                host=f\"{PG_SERVICE_NAME}.{NAMESPACE}.svc.cluster.local\",\n",
    "                database=PG_DATABASE_NAME,\n",
    "                user=\"postgres\",\n",
    "                password=POSTGRES_PASSWORD,\n",
    "                port=\"5432\",\n",
    "                connect_timeout=5\n",
    "            )\n",
    "            return conn\n",
    "        except psycopg2.OperationalError as e:\n",
    "            if attempt == retries - 1:\n",
    "                raise\n",
    "            print(f\"Connection failed (attempt {attempt + 1}), retrying...\")\n",
    "            time.sleep(delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51a94f-3bb3-4e7c-a98e-1c69d13c18a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **5. Generate Sample Data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494690f-0d06-4cf3-ad50-23e3879f25a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `generate_sample_data` function simulates realistic product, customer, stock, and order data with controlled imperfections. <br>\n",
    "This data can be used for testing and analysis within the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a3a91-0dca-43e1-8370-404b0c97fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_data():\n",
    "    \"\"\"Generate realistic sample data with controlled imperfections\"\"\"\n",
    "    # Random data generation for products, customers, orders, and stock entries\n",
    "    # Includes deliberate imperfections (e.g., missing emails, invalid product categories)\n",
    "    # The returned data is structured in a way that makes it easy to insert into the database\n",
    "    return {\n",
    "        \"products\": products,\n",
    "        \"customers\": customers,\n",
    "        \"stock\": stock,\n",
    "        \"orders\": orders,\n",
    "        \"order_products\": order_products\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318187ca-e5ee-4846-b0a9-293efe1f59d9",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e027a2b-d412-4621-b26f-00e1ddebeda8",
   "metadata": {
    "tags": []
   },
   "source": [
    "By following these steps, you'll deploy a PostgreSQL database to a Kubernetes cluster, initialize it with tables, and load sample data for analysis. \n",
    "\n",
    "This exercise helps you become familiar with automating Kubernetes deployments using Python, handling PostgreSQL databases, and generating and loading data for testing purposes.\n",
    "\n",
    "In the next exercise, you will learn how to use Spark on HPE Private Cloud AI to prepare these datasets for visualization and modelling. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc409ac-6bb7-41db-a86f-a92ed4152852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
