{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be01229-0819-4586-8d10-32c2a0513ed9",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/logo.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806b008-9c4f-42f5-838a-5b42b0d5188e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cleanup\n",
    "\n",
    "Let’s put everything back the way it was!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf552cc0-f949-4d48-9637-d5f987603046",
   "metadata": {},
   "source": [
    "## **1. Remove Presto Connectors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979b842-0d53-46e8-8126-d4639c93f0cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Navigate back to the AI Essentials dashboard.\n",
    "1. In the sidebar navigation menu, select `Data Engineering` > `Data Sources`.\n",
    "1. Under `Structured Data`, click on the 3 dots.\n",
    "1. Click `Remove`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd037af-d27b-4687-9496-0a0f9777b396",
   "metadata": {},
   "source": [
    "### 1. Remove the SQL connecter \n",
    "<img src=\"./images/exercise5/rm_sql.png\" alt=\"Drawing\" style=\"width: 35%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2486b9e-dab7-45d8-89a8-a2fb7c8a1330",
   "metadata": {},
   "source": [
    "### 2. Remove the Delta Table connecter \n",
    "<img src=\"./images/exercise5/rm_delta.png\" alt=\"Drawing\" style=\"width: 35%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a2578-bb71-4467-8ec2-5409e7d6a799",
   "metadata": {},
   "source": [
    "## **2. Clean the rest**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f77b6b-690e-4b2c-a3ac-5b217c27f684",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <b>Important:</b> Set your <b>Username</b>, your <b>Domain</b> and your <b>Delta Path</b> here !\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa58ce2-9ae7-4047-b1bb-958fa169aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME=\"\"\n",
    "DOMAIN=\"\"\n",
    "DELTA_PATH=f\"/mnt/shared/{USERNAME}-retail/delta-tables/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4635a-3155-4d80-b495-d958ed66f569",
   "metadata": {
    "tags": []
   },
   "source": [
    "Set the Global variables required to run the exercise smootly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd61ae3-e18d-477d-b462-2dcb9f857f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration\n",
    "NAMESPACE = get_namespace_from_service_account()\n",
    "POSTGRES_PASSWORD = \"postgres\"\n",
    "PG_SERVICE_NAME = f\"{USERNAME}-retail-postgres\"\n",
    "PG_DATABASE_NAME = f\"{USERNAME}-retail\"\n",
    "PVC_PREFIX = \"postgres-pvc\"  # This should match the prefix used in deployment\n",
    "\n",
    "# Print the result\n",
    "print(\"NAMESPACE:\", NAMESPACE)\n",
    "print(\"POSTGRES_PASSWORD:\", POSTGRES_PASSWORD)\n",
    "print(\"PG_SERVICE_NAME:\", PG_SERVICE_NAME)\n",
    "print(\"PG_DATABASE_NAME:\", PG_DATABASE_NAME)\n",
    "\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0f5a0-6771-4c64-a790-dbfec1216b52",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f3e5d-58ab-4d20-9e15-159432a17d30",
   "metadata": {},
   "source": [
    "Function that reads the Kubernetes namespace from the service account mount point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9ef1d-e4d4-4d42-acb6-c9abae749939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_namespace_from_service_account():\n",
    "    \"\"\"\n",
    "    Reads the Kubernetes namespace from the service account mount point.\n",
    "    Returns 'default' if not running in a Kubernetes pod or if the file doesn't exist.\n",
    "    \"\"\"\n",
    "    namespace_file = '/var/run/secrets/kubernetes.io/serviceaccount/namespace'\n",
    "    try:\n",
    "        with open(namespace_file, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    except IOError:\n",
    "        return 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c176daa-c044-4fe9-ba66-4a528c24a851",
   "metadata": {},
   "source": [
    "Function to clean up a PostgreSQL deployment on Kubernetes by deleting the deployment and service, waiting for termination, and verifying the deletion, while handling potential errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42430f82-9273-45ec-b36f-3301b2c85256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_postgresql_deployment():\n",
    "    \"\"\"Clean up PostgreSQL deployment from Kubernetes\"\"\"\n",
    "    try:\n",
    "        print(\"Starting PostgreSQL cleanup...\")\n",
    "        \n",
    "        # 1. Delete the deployment\n",
    "        print(f\"Deleting deployment {PG_SERVICE_NAME}...\")\n",
    "        subprocess.run(\n",
    "            f\"kubectl delete deployment {PG_SERVICE_NAME} -n {NAMESPACE} --ignore-not-found\",\n",
    "            shell=True, check=True\n",
    "        )\n",
    "        \n",
    "        # 2. Delete the service\n",
    "        print(f\"Deleting service {PG_SERVICE_NAME}...\")\n",
    "        subprocess.run(\n",
    "            f\"kubectl delete service {PG_SERVICE_NAME} -n {NAMESPACE} --ignore-not-found\",\n",
    "            shell=True, check=True\n",
    "        )\n",
    "        \n",
    "        # 3. Wait for resources to be deleted\n",
    "        print(\"Waiting for resources to terminate...\")\n",
    "        sleep(10)  # Give Kubernetes time to clean up\n",
    "        \n",
    "        # 4. Verify deletion\n",
    "        print(\"Verifying deletion...\")\n",
    "        verify_deletion()\n",
    "        \n",
    "        print(\"\\nPostgreSQL deployment cleaned up successfully!\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during cleanup: {e.stderr.decode()}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e212a1a-eb14-43c3-8041-16c100ac998e",
   "metadata": {},
   "source": [
    "Function to verify the deletion of a PostgreSQL deployment by checking for the existence of its deployment, service, and pods in Kubernetes, and issuing warnings if any resources are still found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0cf1eb-60ec-427d-83df-e190b9d6f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_deletion():\n",
    "    \"\"\"Verify that all resources have been deleted\"\"\"\n",
    "    try:\n",
    "        # Check deployment\n",
    "        result = subprocess.run(\n",
    "            f\"kubectl get deployment {PG_SERVICE_NAME} -n {NAMESPACE}\",\n",
    "            shell=True, capture_output=True, text=True\n",
    "        )\n",
    "        if \"NotFound\" not in result.stderr:\n",
    "            print(\"Warning: Deployment might still exist\")\n",
    "        \n",
    "        # Check service\n",
    "        result = subprocess.run(\n",
    "            f\"kubectl get service {PG_SERVICE_NAME} -n {NAMESPACE}\",\n",
    "            shell=True, capture_output=True, text=True\n",
    "        )\n",
    "        if \"NotFound\" not in result.stderr:\n",
    "            print(\"Warning: Service might still exist\")\n",
    "        \n",
    "        # Check pods\n",
    "        result = subprocess.run(\n",
    "            f\"kubectl get pods -n {NAMESPACE} -l app={PG_SERVICE_NAME}\",\n",
    "            shell=True, capture_output=True, text=True\n",
    "        )\n",
    "        if \"No resources found\" not in result.stdout:\n",
    "            print(\"Warning: Pods might still exist\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Verification error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169bd8cb-c3ef-4ab4-9dfd-13d1c91f2e35",
   "metadata": {},
   "source": [
    "Function to clean up persistent data in Kubernetes by finding and deleting Persistent Volume Claims (PVCs) and their associated Persistent Volumes (PVs), ensuring proper resource deletion and handling errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5508215-89c4-452e-b92a-9a8995625579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_persistent_data():\n",
    "    \"\"\"Delete persistent volumes and claims\"\"\"\n",
    "    try:\n",
    "        print(\"\\nStarting persistent data cleanup...\")\n",
    "        \n",
    "        # 1. Find and delete all PVCs with the matching prefix\n",
    "        print(f\"Looking for PVCs with prefix '{PVC_PREFIX}'...\")\n",
    "        result = subprocess.run(\n",
    "            f\"kubectl get pvc -n {NAMESPACE} --no-headers -o custom-columns=':metadata.name' | grep '^{PVC_PREFIX}'\",\n",
    "            shell=True, capture_output=True, text=True\n",
    "        )\n",
    "        \n",
    "        pvcs = result.stdout.splitlines()\n",
    "        if pvcs:\n",
    "            print(f\"Found {len(pvcs)} PVC(s) to delete:\")\n",
    "            for pvc in pvcs:\n",
    "                print(f\"- {pvc}\")\n",
    "            print(\"\\nDeleting PVCs...\")\n",
    "            subprocess.run(\n",
    "                f\"kubectl delete pvc {' '.join(pvcs)} -n {NAMESPACE}\",\n",
    "                shell=True, check=True\n",
    "            )\n",
    "        else:\n",
    "            print(\"No PVCs found matching the prefix\")\n",
    "        \n",
    "        # 2. Wait for PVCs to be deleted\n",
    "        print(\"Waiting for PVCs to be deleted...\")\n",
    "        sleep(10)\n",
    "        \n",
    "        # 3. Find and delete associated PVs (if not automatically deleted)\n",
    "        print(\"Checking for associated PVs...\")\n",
    "        result = subprocess.run(\n",
    "            f\"kubectl get pv --no-headers -o custom-columns=':metadata.name,:spec.claimRef.name' | grep {PVC_PREFIX} | awk '{{print $1}}'\",\n",
    "            shell=True, capture_output=True, text=True\n",
    "        )\n",
    "        \n",
    "        pvs = result.stdout.splitlines()\n",
    "        if pvs:\n",
    "            print(f\"Found {len(pvs)} PV(s) to delete:\")\n",
    "            for pv in pvs:\n",
    "                print(f\"- {pv}\")\n",
    "            print(\"\\nDeleting PVs...\")\n",
    "            subprocess.run(\n",
    "                f\"kubectl delete pv {' '.join(pvs)}\",\n",
    "                shell=True, check=True\n",
    "            )\n",
    "        else:\n",
    "            print(\"No associated PVs found\")\n",
    "        \n",
    "        print(\"\\nPersistent data cleanup completed\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        if \"NotFound\" not in e.stderr.decode() and \"no matches found\" not in e.stderr.decode():\n",
    "            print(f\"Error during persistent data cleanup: {e.stderr.decode()}\")\n",
    "        else:\n",
    "            print(\"No persistent resources found to delete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e5827-2345-4ddd-8e04-c586ad77ed31",
   "metadata": {},
   "source": [
    "Function to clean up Delta tables by removing the specified Delta directory from the filesystem, handling any errors that may occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4a4ae-55d8-4f19-b1b2-cd172213f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_delta_tables():\n",
    "    \"\"\"Clean up Delta tables\"\"\"\n",
    "    import shutil\n",
    "    try:\n",
    "        print(f\"\\nCleaning Delta tables at: {DELTA_PATH}\")\n",
    "        \n",
    "        if os.path.exists(DELTA_PATH):\n",
    "            print(\"Removing Delta directory...\")\n",
    "            shutil.rmtree(DELTA_PATH)\n",
    "            print(\"Delta tables removed successfully!\")\n",
    "        else:\n",
    "            print(\"Delta directory not found - nothing to clean\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning Delta tables: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06148d03-c2e2-41bd-84f7-a173a3e50d39",
   "metadata": {},
   "source": [
    "Function to perform a complete cleanup by removing PostgreSQL deployment, deleting persistent data, and cleaning Delta tables, ensuring all resources are properly cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc49d8-962c-4561-b87f-f7d6587e546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_cleanup():\n",
    "    \"\"\"Perform complete cleanup including persistent data and analytics resources\"\"\"\n",
    "    print(\"=== Starting Full Cleanup ===\")\n",
    "    clean_postgresql_deployment()\n",
    "    delete_persistent_data()\n",
    "    clean_delta_tables()\n",
    "    print(\"=== Full Cleanup Completed ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8689bd6-0dab-48bb-8768-26e24833cfb4",
   "metadata": {},
   "source": [
    "Function to present a menu to the user for selecting between a basic cleanup (deployment/service) or a full cleanup (including data), and execute the corresponding cleanup process based on their choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab4b54f-651f-48ed-b749-c0bf7c0dd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the main menu\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Retail Analytics Kubernetes Cleanup Tool\")\n",
    "    print(f\"Namespace: {NAMESPACE}\")\n",
    "    print(f\"PostgreSQL Resource: {PG_SERVICE_NAME}\")\n",
    "    print(f\"PVC Prefix: {PVC_PREFIX}*\")\n",
    "    print(f\"Delta Path: {DELTA_PATH}\")\n",
    "    \n",
    "    choice = input(\"\\nChoose cleanup option:\\n\"\n",
    "                   \"1. Basic cleanup (deployment/service)\\n\"\n",
    "                   \"2. Full cleanup (including data)\\n\"\n",
    "                   \"Enter choice (1/2): \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        clean_postgresql_deployment()\n",
    "    elif choice == \"2\":\n",
    "        full_cleanup()\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dfac0-f760-45ed-9c7f-ecc7d86535a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Conclusion**\n",
    "\n",
    "Thank you for exploring our **Smart Retail Data Analyst** Demo! We’ve just seen how cutting-edge technologies like **Apache Spark**, **Delta Lake**, **Presto**, and **NVIDIA Inference Microservices** come together to unlock the true power of retail data.\n",
    "\n",
    "Throughout the exercises, we:\n",
    "- Analyzed customer purchasing patterns\n",
    "- Predicted sales trends with real-time data\n",
    "- Optimized inventory with fast, interactive SQL queries\n",
    "- Used natural language to extract AI-powered insights effortlessly\n",
    "\n",
    "Now that all exercises are complete and the environment has been successfully cleaned up, this concludes our demo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
