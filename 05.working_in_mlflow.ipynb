{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f49fcb3-4274-4e7c-9869-e8dd69fa11f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./images/logo.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08918df-ae69-4e02-b350-82b0f1cdcdc9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Exercise 5:** Tracking, Registering and Inferencing Models in MLflow\n",
    "\n",
    "You've trained a model. What's next? You could gather further produce data and train the model further? You could serve the model through an endpoint to allow others and/or frontend applications to use it? Perhaps you'd want to use it as a base model to train a whole new model with a whole new dataset? \n",
    "\n",
    "To do any of these requires a deeper dive into ML into MLflow - the most popular and contributed open-source machine learning platform that comes natively installed with **HPE Ezmeral Unified Analytics.** And in this exercise, we'll do just that.\n",
    "\n",
    "In this exercise, you will learn how to perform the following on MLflow:\n",
    "\n",
    "- Manage artifacts & metrics on MLflow\n",
    "- Register the model\n",
    "- Manage models, including moving them to and from Production staging\n",
    "- Inference the model using an MLflow endpoint\n",
    "\n",
    "By the end of this exercise, you will have a firm understanding of the art of Machine Learning Operations (MLOps) with MLflow.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af620db3-6c64-4323-8869-d14dd4ee6cb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Prerequsites**\n",
    "\n",
    "As instructed in the [Introductory notebook](./00.introduction.ipynb), ensure that you have run `pip install -r requirements.txt` in a Terminal window, located in the same working directory, prior to running this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5548d-0877-4551-9c81-9e6f37c25823",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Important:</b> This exercise requires the completion of Exercise 4:  Building a Image Classification Model with Tensorflow and MLflow.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490016b4-5cb1-4699-9c00-ecfc8a19cd23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **1. Declaring Variables and Importing Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d59f3-ff7f-4465-bf4a-5459927866f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's re-declare the variables related to our MLflow experiement such that we can access them in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c129f625-a3e9-4b4b-a95e-ee05fbe6ba0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment variables for MLflow\n",
    "experiment_name = \"retail-experiment\"\n",
    "model_name = \"produce-detection\"\n",
    "artifact_path = \"model\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9589dae-75c1-49fd-8ea8-72dc42c2c429",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, we'll import the necessary libraries. To learn more about these libraries, check out Section 1 of [Exercise 4](./04.model_training.ipynb).\n",
    "\n",
    "Ignore any warnings that appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150f8bf7-ed2c-4c87-934c-9c79e6a63a93",
   "metadata": {
    "papermill": {
     "duration": 7.613981,
     "end_time": "2023-03-13T20:40:28.950010",
     "exception": false,
     "start_time": "2023-03-13T20:40:21.336029",
     "status": "completed"
    },
    "tags": [
     "imports"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 10:19:44.892476: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-07 10:19:44.896261: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-07 10:19:44.907740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741342784.926713    2179 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741342784.932720    2179 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 10:19:44.953531: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "from mlflow.entities.model_registry.model_version_status import ModelVersionStatus\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7806e004-2439-4f4a-b4dc-05561777a1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token successfully refreshed.\n"
     ]
    }
   ],
   "source": [
    "%update_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b675d6f-e171-411e-b9a3-1667777094b7",
   "metadata": {
    "papermill": {
     "duration": 0.074875,
     "end_time": "2023-03-13T21:22:22.585971",
     "exception": false,
     "start_time": "2023-03-13T21:22:22.511096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **2. Checking In**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309e45c-06f1-4b38-a443-165d90a0bda4",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the last exercise, we trained a model and saved it as an MLflow artifact. Let's go inspect it in MLflow.\n",
    "\n",
    "1. Navigate back to the Unified Analytics dashboard.\n",
    "1. In the sidebar navigation menu, select `Data Science` > `Experiments`.\n",
    "1. The **MLflow Experiments** page will open in a new tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5d6bbf-97af-4f56-8d9e-5c4ae74bd029",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here, you will be able to see all of your **Experiements**. Clicking on any one Experiment (such as our `retail-experiment` experiment), you can see all of the experimental **runs** you have executed under that Experiment\n",
    "\n",
    "4. Click `Columns` dropdown in the middle-right of options row above the Run table. \n",
    "\n",
    "This is where you can add more quick bits of information presented with each Run, making them easy to compare. \n",
    "\n",
    "5. Check `accuracy`, which is the accuracy of the model on our test set, and `val_loss`, the error with our validations during the training run. \n",
    "\n",
    "<img src=\"./images/exercise5/mlflow1.png\" alt=\"Drawing\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752ceb3-fb57-4251-9976-39ac219f26ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "6. Click on the Run Name to explore it further. `produce-detection-...`\n",
    "\n",
    "In this pane, we can see the **parameters** we set up for this model, as well as the **metrics**, all of the **artifacts** associated with run (including the model file and data) and the **Full Path** to the model, which we can call to access the model from this specific run. \n",
    "\n",
    "<img src=\"./images/exercise5/model.png\" alt=\"Drawing\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48380789-54c2-4771-89fb-a4189c2def3e",
   "metadata": {
    "papermill": {
     "duration": 0.074875,
     "end_time": "2023-03-13T21:22:22.585971",
     "exception": false,
     "start_time": "2023-03-13T21:22:22.511096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **3. Registering a Model in the Model Regsitry**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35afea6-01f9-4448-af76-3645da49f4ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "Back here in the notebook, we're going to learn how to add the model to the MLflow **Model Registry**. A Model Regsitry is a specialized library to store, track, and manage all the different versions of your models.  \n",
    "\n",
    "Storing your models in a Model Registry has many major advantages, including:\n",
    "\n",
    "**Model Storage**: Just like a library stores books, a model registry stores trained machine learning models. These models are like the recipes you create to solve specific problems.\n",
    "\n",
    "**Version Control**:  As you experiment and improve your models, you create new versions. A model registry keeps track of all these different versions, allowing you to compare them and see which one performs best and \"rollback\" if future experiments give an undesirable output. \n",
    "\n",
    "**Documentation**:  In addition to the models themselves, a registry can store important information about each model, like the data it was trained on, its performance metrics, and who created it. This documentation helps everyone understand what the model does and how it was built.\n",
    "\n",
    "**Collaboration**:  A model registry acts as a central hub for data scientists and engineers working on the same project. They can all access and use the models stored there, making collaboration smoother.\n",
    "\n",
    "**Deployment**:  Once you've chosen the best model version, the registry can help you deploy it into production, meaning you can use it to make real-world predictions.\n",
    "\n",
    "Overall, a model registry helps organizations manage the lifecycle of their machine learning models, from creation to deployment. It ensures everyone's on the same page, models are well-documented, and the best versions are easily accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9744d-906d-4cd2-89b7-c8ea13a1f95c",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, let's bring up the runs assosicated with our `retail-experiment` experiment and get the ID of the most recent run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269889a0-f6ca-4c5f-a965-61e5f57ac528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last active run ID for experiment 'retail-experiment': dcb9bf579a2449e88cb47e697b81af39\n"
     ]
    }
   ],
   "source": [
    "# Search for runs in the specified experiment, ordering by start time in descending order\n",
    "runs = mlflow.search_runs(experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id],\n",
    "                          order_by=[\"start_time desc\"],\n",
    "                          filter_string=\"\")\n",
    "\n",
    "# Check if there are any runs\n",
    "if not runs.empty:\n",
    "    # Get the run ID of the last active run\n",
    "    last_run_id = runs.iloc[0][\"run_id\"]\n",
    "    print(\"Last active run ID for experiment '{}': {}\".format(experiment_name, last_run_id))\n",
    "else:\n",
    "    print(\"No runs found for experiment '{}'.\".format(experiment_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c9949-feb2-40e9-895b-1dec7ba2b5e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "We'll use then create a URI for our model to specify where it is using the run ID and artifact path (declared above as just `model`). \n",
    "\n",
    "Using this URI, we can **register the model** in the **MLflow Model Registry** under a given model name (declared above as `retail-recognition`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85020498-9b64-48eb-9e23-070631b954f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'produce-detection'.\n",
      "2025/03/07 10:20:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: produce-detection, version 1\n",
      "Created version '1' of model 'produce-detection'.\n"
     ]
    }
   ],
   "source": [
    "# set parameters model_uri and model details and register model in mlflow\n",
    "model_uri = \"runs:/{run_id}/{artifact_path}\".format(run_id=last_run_id, artifact_path=artifact_path)\n",
    "model_details = mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e837b-5c87-4fcc-b308-2d0ec2d14fd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Then, we're going to make a new **Version** of our model. You will usually do this after you run the same model, but perhaps with different parameters. \n",
    "\n",
    "We can differentiate between models it by giving them a different **Description** and/or specifying a **Version** number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1179e0c-702d-479d-bb59-58ddc6cbaf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'produce-detection' already exists. Creating a new version of this model...\n",
      "2025/03/07 10:20:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: produce-detection, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model status: READY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'produce-detection'.\n"
     ]
    }
   ],
   "source": [
    "# Create a second Version of the model\n",
    "model_uri = \"runs:/{run_id}/{artifact_path}\".format(run_id=last_run_id, artifact_path=artifact_path)\n",
    "model_details = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "# Update the second model with a description and a Version number.\n",
    "client = MlflowClient()\n",
    "\n",
    "client.update_model_version(\n",
    "    name=model_details.name,\n",
    "    version=2,\n",
    "    description=\"Fruit & Vegetables Cashierless Store\",\n",
    ")\n",
    "\n",
    "# Get the details of the model version\n",
    "model_version_details = client.get_model_version(\n",
    "    name=model_details.name,\n",
    "    version=2\n",
    ")\n",
    "\n",
    "# Convert the status to a readable string and print it\n",
    "status = ModelVersionStatus.from_string(model_version_details.status)\n",
    "print(\"Model status: %s\" % ModelVersionStatus.to_string(status))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c03e3e-f97a-4ddd-91fc-864260bb9ae5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Staging\n",
    "\n",
    "Model Staging is an important step in the machine learning workflow, as it allows for complete model governance and visibility between multiple parties (e.g. what models are currently in deployment, being worked on, older archived versons, etc). Staging also ensures that only specific versions of any given model are being inferenced. \n",
    "\n",
    "There are three Stages of development you can classify a model (and/or a specific version of a model) under in MLflow:\n",
    "- `None`: No action has yet been taken on this model version.\n",
    "- `Staging`: This model/version is currently under active development and being prepared for Production.\n",
    "- `Production`: This model/version is live and being used/inferenced by external applications. \n",
    "\n",
    "If you check the page, currently all versions of our model have a *Stage* status of `None`. \n",
    "\n",
    "Staging is an important step in the machine learning workflow, as it allows for complete model governance and visibility between multiple parties (e.g. what models are currently in deployment, being worked on, older archived versons, etc). Staging also ensures that only specific versions of any given model are being inferenced. \n",
    "\n",
    "Given our previous test result, I'd say we're good to send the **latest** version of our model to the `Production` stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7908bcd3-b72c-4fab-a2f1-8e289f343bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: produce-detection, version: 2 has been moved to Production\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2179/1257690862.py:5: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = client.get_latest_versions(name=model_name, stages=[\"None\"])\n",
      "/tmp/ipykernel_2179/1257690862.py:9: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "# create an instance of the MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get the latest model created for our experiment\n",
    "latest_versions = client.get_latest_versions(name=model_name, stages=[\"None\"])\n",
    "latest_version = latest_versions[-1]\n",
    "\n",
    "# Transition the desired model version to production stage\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=latest_version.version,\n",
    "    stage='Production',\n",
    ")\n",
    "\n",
    "print(f\"Model: {latest_version.name}, version: {latest_version.version} has been moved to Production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885b533-b007-4832-a79c-d3904b63cd73",
   "metadata": {
    "tags": []
   },
   "source": [
    "As for our older, previous versions we will move them to the `Archive` stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75387be9-09e5-420d-bd12-f53b4c28c8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: produce-detection, version: 1 has been moved to Archived\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2179/2671714479.py:8: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "# Transition model versions to a different stage if their current stage is not \"production\"\n",
    "model_versions = client.search_model_versions(\"\")\n",
    "\n",
    "# Transition model versions to a different stage if their current stage is not \"production\"\n",
    "for mv in model_versions:\n",
    "    if mv.name == model_name:\n",
    "        if mv.version != latest_version.version:\n",
    "            client.transition_model_version_stage(\n",
    "                name=mv.name,\n",
    "                version=mv.version,\n",
    "                stage=\"Archived\"\n",
    "            )\n",
    "            print(f\"Model: {mv.name}, version: {mv.version} has been moved to Archived\")\n",
    "\n",
    "            # Update Model Version Description\n",
    "            client.update_model_version(\n",
    "                name=mv.name,\n",
    "                version=mv.version,\n",
    "                description=\"Model Moved to Archived\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb85f7-49cb-4a6e-908a-e19c30b41698",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, we can see all versions of our model have an updated *Stage* status. \n",
    "\n",
    "<img src=\"./images/exercise5/registry2.png\" alt=\"Drawing\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668b9dc-2e73-4a65-8087-027130bf0937",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **6. Model Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d361e825-034f-443d-8168-18cefc88d048",
   "metadata": {
    "papermill": {
     "duration": 0.074875,
     "end_time": "2023-03-13T21:22:22.585971",
     "exception": false,
     "start_time": "2023-03-13T21:22:22.511096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Similar to the previous exercise, we will now test our model - but instead of calling the model from a saved variable in the notebook's memory, this time we will call it from the MLflow Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "137ce3ea-90e1-430d-84a8-e59bb3577cda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token successfully refreshed.\n"
     ]
    }
   ],
   "source": [
    "%update_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bc99af2-5941-49d0-83b7-a3ccbada1d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edde6e3fdae54ecf96df36791d36c054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 10:22:43.799619: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/admin/.local/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Get the source URI or location of the model version\n",
    "logged_model = latest_version.source\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6b33e-35a8-4ef1-97bb-e80ac0ce0ecc",
   "metadata": {
    "tags": []
   },
   "source": [
    "We'll redeclare our labels from the previous notebook so we can better interpret the answer our model gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06268df6-d14a-4659-bec4-14a3f0fea55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = {'apple': 0, 'banana': 1, 'carrot': 2, 'cucumber': 3, 'lemon': 4, 'orange': 5}\n",
    "labels = dict((v, k) for k, v in labels.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af90be9-be4b-4e1a-a493-b8c91fdcc5cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, like last exercise, **go out** onto Google Images and find a **different** image of a **orange**, an **apple** or a **lemon**. Copy the link into the `online_url` variable.\n",
    "\n",
    "If you are in an offline/proxy environment, upload your file to the same directory as this notebook and call it **test_image.jpg**. An has been supplied if you just wish to run the cell without finding your own image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd7a5672-c828-455f-bbbb-fdf8f0f8ad6e",
   "metadata": {
    "papermill": {
     "duration": 0.168369,
     "end_time": "2023-03-13T21:24:26.545710",
     "exception": false,
     "start_time": "2023-03-13T21:24:26.377341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(location, model):\n",
    "    \n",
    "    #Check to see if a web URL or a local file is being parsed \n",
    "    if \"http\" in location:\n",
    "        response = requests.get(location)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "    else:\n",
    "        from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "        img=load_img(location,target_size=(224,224,3))\n",
    "    \n",
    "    #Convert the image into the dimensions of the model's input layer.\n",
    "    img=img_to_array(img)\n",
    "    img=img/255\n",
    "    img=np.expand_dims(img,[0])\n",
    "    \n",
    "    # Infer the model with the image\n",
    "    answer=model.predict(img)\n",
    "\n",
    "    # Format the answer\n",
    "    y_class = answer.argmax(axis=-1)\n",
    "    y = \" \".join(str(x) for x in y_class)\n",
    "    y = int(y)\n",
    "    res = labels[y]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c43c00-f0a0-4640-94f6-6760fb7fcdd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894ms/step\n",
      "The model predicts: orange\n"
     ]
    }
   ],
   "source": [
    "# Load the path for our image, be it a web URL or a local file\n",
    "online_url = \"\"\n",
    "local_url = os.getcwd() + \"/images/test_image.jpg\"\n",
    "\n",
    "if online_url:\n",
    "    image_url = online_url\n",
    "else:\n",
    "    image_url = local_url\n",
    "\n",
    "# Parse in our loaded_model, which is the latest version of our model pulled from MLflow. \n",
    "img = predict(image_url, loaded_model)\n",
    "print(\"The model predicts: \" + img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915e7f0-fec1-4c34-b9ba-d3523879d63e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Did the model correctly guess what was in your image? If so, great! If not... *still* also great!\n",
    "\n",
    "As you have now observed through using a Model Registry, **incorrect predictions** from models provide vital feedback that can help you to understand the model's behaviour and improve either the training dataset or the model. Using the MLflow Model Registry, we can compare multiple versions of the same model and understand how tweaking the dataset and model parameters can affect performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b892674-e0d6-4cb8-87ed-63ab76aa59de",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc02b8e-559d-486b-97f0-d52706cb3981",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this exercise, you got to explore the ins and outs of the machine learning workflow platform, MLflow. You learned how to register models from experiment runs into the MLflow Model Registry, update versions of models in the registry from existing runs, and modify the staging of models in the registry to allow teams working on this model to keep track of what models are deployed into production. \n",
    "\n",
    "Lastly, you learned how to pull a model from the saved artifacts associated a model in the registry using the model's MLflow URI.\n",
    "\n",
    "In the next exercise, you will use that URI to **serve** the latest version of your model from the repository using **KServe** - making it callable from your own retail application!\n",
    "\n",
    "For more on managing models in the MLflow Model Registry, see the offical <a href=\"https://mlflow.org/docs/latest/model-registry.html\">MLflow documentation </a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d90450-7582-458e-93d1-cc13655a0794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2aeacf-4c14-4eb1-ad4e-9812a20739de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "516cdc2a-1e96-44da-a365-7bf3a046f61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact URI: s3://mlflow.ddpcai/0/b27f6141bb8c432a818255ee2d9df0f8/artifacts\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set the experiment name to 'Default'\n",
    "experiment_name = \"Default\"\n",
    "\n",
    "# Set the run ID\n",
    "run_id = \"b27f6141bb8c432a818255ee2d9df0f8\"\n",
    "\n",
    "# Get the run details\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "# Fetch the artifact location from the run's metadata\n",
    "artifact_uri = run.info.artifact_uri\n",
    "print(f\"Artifact URI: {artifact_uri}\")\n",
    "\n",
    "# Define the model path within the artifact (if you know it; assume it's 'model')\n",
    "model_path = f\"{artifact_uri}/model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f5fb98a-d29c-4a7c-ad34-4a35546bfe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'fine_tuned_fb125_model'.\n",
      "2025/03/08 17:07:57 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: fine_tuned_fb125_model, version 1\n",
      "Created version '1' of model 'fine_tuned_fb125_model'.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'mlflow' has no attribute 'set_model_version_stage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model_uri \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mregister_model(model_path, model_name)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Optionally, set the stage (e.g., \"Production\", \"Staging\")\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_model_version_stage\u001b[49m(model_uri, stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStaging\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel registered with URI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mlflow' has no attribute 'set_model_version_stage'"
     ]
    }
   ],
   "source": [
    "# Register the model with MLflow\n",
    "model_name = \"fine_tuned_fb125_model\"  # Set your desired model name\n",
    "\n",
    "# Register the model to the model registry\n",
    "model_uri = mlflow.register_model(model_path, model_name)\n",
    "\n",
    "# Optionally, set the stage (e.g., \"Production\", \"Staging\")\n",
    "mlflow.set_model_version_stage(model_uri, stage=\"Staging\")\n",
    "\n",
    "print(f\"Model registered with URI: {model_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7aeb0b-a070-46a6-810c-4f134eb8a4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1227f7e-22c3-4dc8-8ffa-545f7756ac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gcr.io/mapr-252711/kubeflow/notebooks/jupyter-tensorflow-cuda-full:ezaf-fy23-q2",
   "experiment": {
    "id": "new",
    "name": "jk-fruit-demo"
   },
   "experiment_name": "jk-fruit-demo",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "random",
     "algorithmSettings": [
      {
       "name": "random_state",
       "value": "10"
      },
      {
       "name": "acq_optimizer",
       "value": "auto"
      },
      {
       "name": "acq_func",
       "value": "gp_hedge"
      },
      {
       "name": "base_estimator",
       "value": "GP"
      }
     ]
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "additionalMetricNames": [],
     "goal": 1,
     "objectiveMetricName": "stage",
     "type": "maximize"
    },
    "parallelTrialCount": 3,
    "parameters": [
     {
      "feasibleSpace": {
       "max": "50",
       "min": "1",
       "step": "1"
      },
      "name": "param_epoch",
      "parameterType": "int"
     },
     {
      "feasibleSpace": {
       "list": [
        "32",
        "64"
       ]
      },
      "name": "param_batch_size",
      "parameterType": "categorical"
     },
     {
      "feasibleSpace": {
       "max": "10",
       "min": "1",
       "step": "1"
      },
      "name": "param_patience",
      "parameterType": "int"
     }
    ]
   },
   "katib_run": false,
   "pipeline_description": "fruit-veg",
   "pipeline_name": "fruit-veg",
   "snapshot_volumes": false,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:add-ldapcert-secret:true",
    "label:add-sssd-secret:true",
    "label:add-user-s3-secret:true"
   ],
   "storage_class_name": "dataplatform",
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/mnt/shared/",
     "name": "kubeflow-pipeline",
     "size": 1,
     "size_type": "Gi",
     "snapshot": false,
     "snapshot_name": "",
     "type": "pvc"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2679.282234,
   "end_time": "2023-03-13T21:24:51.692744",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-13T20:40:12.410510",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
